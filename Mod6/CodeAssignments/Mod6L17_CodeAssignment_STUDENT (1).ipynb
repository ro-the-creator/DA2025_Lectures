{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Assignment 17 — K-Means Model Comparison with CH & DB + Assumption Testing (Mall Customers)\n",
    "\n",
    "**Format:** Instructor Guidance → Your Task (step-by-step) → We Share (reflection)\n",
    "\n",
    "**Goal:**  Compare **two feature sets** for K-Means at the **same K**:  \n",
    "- **Model 1:** 2 features → `['Annual Income (k$)', 'Spending Score (1-100)']`  \n",
    "- **Model 2:** 3 features → `['Age', 'Annual Income (k$)', 'Spending Score (1-100)']`  \n",
    "Evaluate with **Silhouette (↑), Calinski–Harabasz (↑), Davies–Bouldin (↓)**, **separation ratio** (↑), **cluster sizes**, and **stability (median ARI) (↑)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor Guidance (Pseudocode + Docs)\n",
    "\n",
    "**Docs**  \n",
    "- `StandardScaler`: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html  \n",
    "- `KMeans`: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html  \n",
    "- `silhouette_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html  \n",
    "- `calinski_harabasz_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html  \n",
    "- `davies_bouldin_score`: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html  \n",
    "- `adjusted_rand_score` (stability): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\n",
    "\n",
    "### Pseudocode Plan (Model Comparison)\n",
    "  1) Load CSV → pick clean numeric columns (2D vs 3D).  \n",
    "  2) **Scale** each feature set **separately** with `StandardScaler`.  \n",
    "  3) Fix **K** (e.g., K=4).  \n",
    "  4) Fit KMeans on each set → get labels & centers.  \n",
    "  5) Compute metrics: `silhouette_score` (↑), `calinski_harabasz_score` (↑), `davies_bouldin_score` (↓).  \n",
    "  6) Assumption checks: **separation ratio** (min between-centroid distance ÷ max within-cluster spread), **cluster sizes** (%), **stability via ARI** across seeds.  \n",
    "  7) Compare models in a table → pick one and justify.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task — Step-by-Step\n",
    "Work in pairs. Keep it minimal and clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Run Helper Functions and do your Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL WITHOUT CHANGES \n",
    "\n",
    "def cluster_size_pct(labels):\n",
    "    \"\"\"Return % size of each cluster (sorted by cluster index).\"\"\"\n",
    "    s = pd.Series(labels).value_counts(normalize=True).sort_index()\n",
    "    return (s * 100).round(1)\n",
    "\n",
    "def within_between_ratio(Z, labels, centers):\n",
    "    \"\"\"\n",
    "    Heuristic separation metric:\n",
    "    min distance among centroids ÷ max within-cluster spread (avg feature std per cluster).\n",
    "    Higher is better (more separated vs within spread).\n",
    "    \"\"\"\n",
    "    within = []\n",
    "    for c in range(centers.shape[0]):\n",
    "        pts = Z[labels == c]\n",
    "        if len(pts) == 0:\n",
    "            within.append(np.nan)\n",
    "        else:\n",
    "            within.append(pts.std(axis=0).mean())\n",
    "    within = np.array(within, dtype=float)\n",
    "    max_within = np.nanmax(within)\n",
    "\n",
    "    D = cdist(centers, centers)  # centroid distance matrix\n",
    "    np.fill_diagonal(D, np.nan)\n",
    "    min_between = np.nanmin(D)\n",
    "    return float(min_between / max_within)\n",
    "\n",
    "def stability_ari(Z, k, seeds=(0, 1, 2, 3, 4)):\n",
    "    \"\"\"\n",
    "    Fit KMeans across multiple seeds and compute median Adjusted Rand Index across pairs.\n",
    "    Higher median ARI = more stable clustering to initialization.\n",
    "    \"\"\"\n",
    "    label_sets = []\n",
    "    for s in seeds:\n",
    "        km = KMeans(n_clusters=k, n_init=10, random_state=s).fit(Z)\n",
    "        label_sets.append(km.labels_)\n",
    "    pairs = [(i, j) for i in range(len(label_sets)) for j in range(i+1, len(label_sets))]\n",
    "    aris = [adjusted_rand_score(label_sets[i], label_sets[j]) for (i, j) in pairs]\n",
    "    return float(np.median(aris))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the Mall Customers CSV & Preview\n",
    "Use the same dataset as last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build 2D and 3D feature sets (numeric only, minimal cleaning)\n",
    "\n",
    "- 2D set:  Annual Income and Spending Score\n",
    "- 3D set:  Age, Annual Income, Spending Score \n",
    "\n",
    "**Be sure to scale!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Choose a single k for BOTH models (you can try 3, 4, 5, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FIXED = None\n",
    "print('Using K =', K_FIXED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Fit Model 1 (2D @ K) and compute metrics\n",
    "\n",
    "- No train-test split needed \n",
    "- Use helper functions above to help calculate metrics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Fit Model 2 (3D @ K) and compute metrics\n",
    "\n",
    "- No train-test split needed \n",
    "- Use helper functions above to help calculate metrics!\n",
    "- Use same k as Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Visualize Model 1 (2D Scatter Plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We Share — Reflection (short, specific)\n",
    "1) **Which model is better and why?** Reference **Sil (↑), CH (↑), DB (↓)**, **separation ratio (↑)**, **stability ARI (↑)**, and **cluster sizes**.  \n",
    "\n",
    "2) **Assumptions & ethics:** Did your chosen model show **non-overlapping, roughly spherical, similarly dense** clusters? If not, what risk could that pose to stakeholders (mis-targeted offers, unfair treatment)?  \n",
    "3) **Next step:** If you had to ship this, what monitoring would you add (e.g., re-check metrics quarterly, watch for tiny cluster drift, re-scale after schema changes)?\n",
    "\n",
    "> Tip: If metrics conflict (e.g., CH prefers K=6, DB prefers K=4), prefer **parsimonious K** with **clear separation**, **stable labels**, and **business actionability**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
